{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final – Uber NYC 2014  \n",
    "## Notebook: Coleta, Limpeza e EDA com KaggleHub (Semana 2)\n",
    "\n",
    "Este notebook realiza:\n",
    "\n",
    "1. Autenticação com o **KaggleHub**  \n",
    "2. Download do dataset **Uber Pickups in New York City (FiveThirtyEight)**  \n",
    "3. Seleção dos arquivos de **abril a setembro de 2014**  \n",
    "4. Consolidação em um único `DataFrame`  \n",
    "5. Limpeza e criação de atributos (`hour`, `weekday`, `month`)  \n",
    "6. Análise exploratória inicial (EDA)  \n",
    "7. Sugestões de prompts para geração de insights com IA\n",
    "\n",
    "> **Importante:** este notebook foi preparado para ser executado no **Google Colab**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalação de dependências\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estiver no Google Colab, descomente a linha abaixo na primeira execução:\n",
    "# !pip install kagglehub pandas numpy matplotlib seaborn --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports e configuração inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "DATA_DIR = Path(\"data_uber_raw\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download do dataset com KaggleHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixa o dataset do Kaggle usando o KaggleHub\n",
    "# Doc oficial: https://www.kaggle.com/docs/api#kagglehub\n",
    "\n",
    "try:\n",
    "    path = kagglehub.dataset_download(\"fivethirtyeight/uber-pickups-in-new-york-city\")\n",
    "    print(\"Dataset baixado em:\", path)\n",
    "except Exception as e:\n",
    "    print(\"[ERRO] Falha no download pelo KaggleHub.\")\n",
    "    print(\"Verifique se suas credenciais do Kaggle estão configuradas corretamente.\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Seleção dos arquivos (abril–setembro 2014)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = Path(path)\n",
    "\n",
    "# Lista todos os CSVs baixados\n",
    "all_csv = sorted(raw_path.glob(\"*.csv\"))\n",
    "all_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar arquivos que contenham 'apr', 'may', 'jun', 'jul', 'aug', 'sep' no nome\n",
    "\n",
    "target_months = [\"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\"]\n",
    "selected_files = [f for f in all_csv if any(m in f.name.lower() for m in target_months)]\n",
    "\n",
    "print(\"Arquivos selecionados:\")\n",
    "for f in selected_files:\n",
    "    print(\" -\", f.name)\n",
    "\n",
    "if not selected_files:\n",
    "    raise FileNotFoundError(\n",
    "        \"Nenhum arquivo de abril a setembro foi encontrado. \"\n",
    "        \"Verifique os nomes dos arquivos baixados.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Leitura e concatenação dos CSVs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for f in selected_files:\n",
    "    print(\"Lendo:\", f.name)\n",
    "    tmp = pd.read_csv(f, encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "    dfs.append(tmp)\n",
    "\n",
    "df_raw = pd.concat(dfs, ignore_index=True)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Limpeza, padronização e criação de atributos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cópia para não mexer no bruto\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Padronizar nomes de colunas\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "rename_map = {}\n",
    "for c in df.columns:\n",
    "    if \"date\" in c and \"time\" in c:\n",
    "        rename_map[c] = \"datetime\"\n",
    "    elif c.lower() == \"lat\":\n",
    "        rename_map[c] = \"lat\"\n",
    "    elif c.lower() == \"lon\":\n",
    "        rename_map[c] = \"lon\"\n",
    "    elif c.lower() == \"base\":\n",
    "        rename_map[c] = \"base\"\n",
    "\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "# Manter apenas as colunas que interessam\n",
    "df = df[[\"datetime\", \"lat\", \"lon\", \"base\"]]\n",
    "\n",
    "# Converter tipos\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")\n",
    "\n",
    "# Remover linhas inválidas e duplicadas\n",
    "df = df.dropna(subset=[\"datetime\", \"lat\", \"lon\", \"base\"]).drop_duplicates()\n",
    "\n",
    "# Criar atributos derivados\n",
    "df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "df[\"weekday\"] = df[\"datetime\"].dt.day_name()\n",
    "df[\"month\"] = df[\"datetime\"].dt.month_name()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. EDA – Análise Exploratória Inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_weekday = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(data=df, x=\"weekday\", order=order_weekday)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Número de corridas por dia da semana\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.countplot(data=df, x=\"hour\")\n",
    "plt.title(\"Número de corridas por hora do dia\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = df.pivot_table(\n",
    "    index=\"weekday\",\n",
    "    columns=\"hour\",\n",
    "    values=\"base\",\n",
    "    aggfunc=\"count\"\n",
    ").reindex(order_weekday)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot, cmap=\"coolwarm\")\n",
    "plt.title(\"Heatmap de corridas por dia da semana e hora\")\n",
    "plt.ylabel(\"Dia da semana\")\n",
    "plt.xlabel(\"Hora do dia\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sugestões de prompts para IA\n",
    "\n",
    "**Prompt 1 – Resumo geral da EDA**  \n",
    "> Você é um analista de dados. Com base nos gráficos gerados sobre corridas da Uber em NYC (por dia da semana, por hora do dia e no heatmap weekday × hour), escreva um resumo de até 10 linhas explicando os principais padrões encontrados, horários de pico e possíveis interpretações.\n",
    "\n",
    "**Prompt 2 – Foco em operações e negócios**  \n",
    "> Atue como consultor de negócios para mobilidade urbana. A partir dos padrões de corridas da Uber por dia da semana e por hora do dia, elabore recomendações para alocação de motoristas, definição de tarifas dinâmicas e campanhas promocionais em horários de baixo movimento.\n",
    "\n",
    "**Prompt 3 – Geração de hipóteses**  \n",
    "> Com base nas distribuições de corridas por hora e por dia da semana, gere de 5 a 8 hipóteses que poderiam ser testadas em análises futuras. As hipóteses devem relacionar comportamento de demanda, eventos sazonais, clima ou perfil dos usuários.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
